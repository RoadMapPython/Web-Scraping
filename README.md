# Web-Scrapping
## Componentes usados na live,e um readme para mais detalhes e o link da live gravada: YouTube:
###### -Obs: tem um dicion√°rio de palavras no final do documento

=======================|üìöIntrodu√ß√£oüìö|=====================<br />
Web-Scrapping √© o termo para usar um programa para baixar e processar conte√∫do da web.
Por exemplo, o Google executa muitos programas de Web-Scrapping para indexar 
p√°ginas da Web para seu mecanismo de busca.

Alguns conceitos 
* webbrowser: Vem com python e abre um navegador para uma p√°gina espec√≠fica.

* requests: Baixa arquivos e p√°ginas da Web da internet.

* bs4: Parses HTML, o formato em que as p√°ginas da Web est√£o escritas.

* selenium: Lan√ßa e controla um navegador da Web. O m√≥dulo de sel√™nio √© capaz de preencher formul√°rios e simular cliques do mouse neste navegador.

Quero tentar introduzir dois conceitos e aborda-los nessa live que vai ser o "webbrowser" e o "requests"

Web-Scrapping √© basicamente √© eu extrair dados de paginas web, conseguindo acessar exatamente o que desejo 
,so que no meu codigo em python ,facil ne?

==========================|‚öôÔ∏èConstru√ß√£o do codigo‚öôÔ∏è|============================<br />
Vou come√ßar com o webbrowser

import webbrowser

webbrowser.open('https://sistemas.riopomba.ifsudestemg.edu.br/dacc/index.php/roadmap-python-ensino')

Aqui abrimos a pagina web que desejamos via c√≥digo python, util ne? 

======================================================================<br />

======================================================================<br />
======================================================================<br />
Agora iremos realizar a instala√ß√£o de uma outra biblioteca que iremos usar durante a cria√ß√£o do c√≥digo
* Vamos la no windows+R 
* Digita cmd 
* E digite o comando:pip install requests

======================================================================<br />
Vamos importar a biblioteca "requests" e usar o metodo get

import requests

response = requests.get('https://sistemas.riopomba.ifsudestemg.edu.br/dacc/index.php/roadmap-python-ensino')
print('Status do codigo:', response.status_code)

Os c√≥digos de status das respostas HTTP indicam se uma requisi√ß√£o HTTP foi corretamente conclu√≠da.
As respostas s√£o agrupadas em cinco classes:

* Respostas de informa√ß√£o (100-199),
* Respostas de sucesso (200-299),
* Redirecionamentos (300-399)
* Erros do cliente (400-499)
* Erros do servidor (500-599).

======================================================================<br />
import requests

response = requests.get('https://sistemas.riopomba.ifsudestemg.edu.br/dacc/index.php/roadmap-python-ensino')
print('Status do codigo:', response.status_code)

print('Cabe√ßalho')
print(response.headers)

O cabe√ßalho mostra as informa√ß√µes do site , v√°rios atributos utilizados.

======================================================================<br />
import requests

response = requests.get('https://sistemas.riopomba.ifsudestemg.edu.br/dacc/index.php/roadmap-python-ensino')
print('Status do codigo:', response.status_code)

print('Cabe√ßalho')
print(response.headers)

print('\nConteudo')
print(response.content)

O conteudo ele mostra todo o conteudo do site em si , todo o c√≥digo html dele ,
sabe quando voc√™ clica em inspecionar? ent√£o √© isso!

======================================================================<br />
Iremos utilizar o BeaultifulSoup da biblioteca bs4, com isso teremos de instalar 
o pacote.
* Windows+R 
* Digita cmd 
* E digite o comando:pip install bs4

======================================================================<br />
import requests
from bs4 import BeautifulSoup

response = requests.get('https://sistemas.riopomba.ifsudestemg.edu.br/dacc/index.php/roadmap-python-ensino')

content = response.content

site = BeautifulSoup(content, 'html.parser')

# HTML da not√≠cia
noticia = site.find('div', attrs={'class': 'feed-post-body'})

# T√≠tulo
titulo = noticia.find('a', attrs={'class': 'feed-post-link'})

print(titulo.text)

# Subt√≠tulo: div class="feed-post-body-resumo"
subtitulo = noticia.find('div', attrs={'class': 'feed-post-body-resumo'})

print(subtitulo.text)
======================================================================<br />
---Dicion√°rio---<br />
requests<br />
response<br />
get<br />
content<br />
headers<br />
